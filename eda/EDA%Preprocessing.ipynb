{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import geopandas as gpd\n",
    "\n",
    "# Load and clean data\n",
    "pas_data = pd.read_csv('../data/pas_boroughs.csv')\n",
    "outcomes_data = pd.read_csv('../data/metropolitan-outcomes-merged.csv')\n",
    "# stop_search_data = pd.read_csv('../data/metropolitan-stop-and-search-merged.csv')\n",
    "# street_data = pd.read_csv('../data/metropolitan-street-merged.csv')\n",
    "\n",
    "# Aggregating and creating crime rates\n",
    "outcomes_data['date'] = pd.to_datetime(outcomes_data['Month'])\n",
    "outcomes_data['year'] = outcomes_data['date'].dt.year\n",
    "outcomes_data['quarter'] = outcomes_data['date'].dt.quarter"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "# Load the CSV file\n",
    "arrests = pd.read_csv(\"../data/Custody_Arrests_2019_2024.csv\", delimiter=';')\n",
    "\n",
    "# Display the information (first few rows) from the CSV file\n",
    "print(\"Information from Custody_Arrests_2019_2024.csv:\")\n",
    "print(arrests.info())\n",
    "\n",
    "# Find the number of rows in the original DataFrame 'arrests' where Age Group is neither 'Adult' nor 'Youth'\n",
    "other_age_rows = arrests[~arrests['Age Group'].isin(['Adult', 'Youth'])]\n",
    "\n",
    "# Get the number of rows\n",
    "num_other_age_rows = other_age_rows.shape[0]\n",
    "\n",
    "print(\"Number of rows with Age Group other than 'Adult' or 'Youth':\", num_other_age_rows)\n",
    "\n",
    "# Filter the DataFrame for 'Adult' age group\n",
    "adult_rows = arrests[arrests['Age Group'] == 'Adult']\n",
    "\n",
    "# Get the count of adult rows\n",
    "num_adult_rows = adult_rows.shape[0]\n",
    "\n",
    "# Filter the DataFrame for 'Youth' age group\n",
    "youth_rows = arrests[arrests['Age Group'] == 'Youth']\n",
    "\n",
    "# Get the count of youth rows\n",
    "num_youth_rows = youth_rows.shape[0]\n",
    "\n",
    "print(\"Number of Adult arrests:\", num_adult_rows)\n",
    "print(\"Number of Youth arrests:\", num_youth_rows)\n",
    "\n",
    "# Proportion of Youth arrests\n",
    "total_arrests = len(arrests)\n",
    "proportion_youth_arrests = num_youth_rows / total_arrests\n",
    "\n",
    "print(\"Proportion of Youth arrests:\", proportion_youth_arrests)\n",
    "\n",
    "# Plotting proportion of Youth arrests\n",
    "labels = ['Youth Arrests', 'Other Ages Arrests']\n",
    "sizes = [num_youth_rows, total_arrests - num_youth_rows]\n",
    "colors = ['orange', 'lightblue']\n",
    "explode = (0.1, 0)  # explode the 1st slice\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%',\n",
    "        shadow=True, startangle=140)\n",
    "plt.title('Proportion of Youth Arrests')\n",
    "plt.show()\n",
    "\n",
    "# Filter out only for Youth arrests\n",
    "youth_arrests = arrests[arrests['Age Group'] == 'Youth'].copy()\n",
    "\n",
    "# Extract year and month\n",
    "youth_arrests['Arrest Year'] = youth_arrests['Arrest Year'].astype(int)\n",
    "youth_arrests['Arrest Month'] = youth_arrests['Arrest Month'].astype(int)\n",
    "\n",
    "# Define quarter\n",
    "youth_arrests['quarter'] = pd.cut(\n",
    "    youth_arrests['Arrest Month'],\n",
    "    bins=[0, 3, 6, 9, 12],\n",
    "    labels=[1, 2, 3, 4],\n",
    "    right=True\n",
    ")\n",
    "\n",
    "# Filter for the time span: quarter 1 of 2021 until quarter 3 of 2023\n",
    "filtered_youth_arrests = youth_arrests[\n",
    "    (youth_arrests['Arrest Year'] >= 2021) &\n",
    "    (youth_arrests['Arrest Year'] <= 2023) &\n",
    "    ~((youth_arrests['Arrest Year'] == 2023) & (youth_arrests['quarter'] > 3))\n",
    "]\n",
    "\n",
    "# Aggregate over quarter and year\n",
    "aggregated_youth_arrests = filtered_youth_arrests.groupby(['Arrest Year', 'quarter']).size().reset_index(name='count')\n",
    "\n",
    "print(\"Aggregated Youth Arrests:\")\n",
    "print(aggregated_youth_arrests)\n",
    "\n",
    "# Plotting aggregated youth arrests by year and quarter\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=aggregated_youth_arrests, x='Arrest Year', y='count', hue='quarter')\n",
    "plt.title('Aggregated Youth Arrests by Year and Quarter')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Arrests')\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Distribution of youth arrests for each 'First Arrest Offence'\n",
    "youth_offence_distribution = youth_arrests['First Arrest Offnece'].value_counts()\n",
    "\n",
    "print(\"Distribution of Youth Arrests by First Arrest Offence:\")\n",
    "print(youth_offence_distribution)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting distribution of youth arrests by 'First Arrest Offence' with increased text size\n",
    "plt.figure(figsize=(10, 8))\n",
    "youth_offence_distribution.plot(kind='bar', color='orange')\n",
    "plt.title('Distribution of Youth Arrests by First Arrest Offence', fontsize=16)\n",
    "plt.xlabel('First Arrest Offence', fontsize=14)\n",
    "plt.ylabel('Number of Arrests', fontsize=14)\n",
    "plt.xticks(rotation=90, fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d5bb3f114ddfdf0f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create a pivot table for youth arrests by quarter and \"First Arrest Offnece\"\n",
    "pivot_table = pd.pivot_table(\n",
    "    filtered_youth_arrests,\n",
    "    index='First Arrest Offnece',\n",
    "    columns=['Arrest Year', 'quarter'],\n",
    "    aggfunc='size',\n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "# Add a 'Total' column for each quarter\n",
    "pivot_table['Total'] = pivot_table.sum(axis=1)\n",
    "\n",
    "# Add a 'Total' row for each quarter\n",
    "pivot_table.loc['Total'] = pivot_table.sum()\n",
    "\n",
    "# Print the pivot table\n",
    "print(pivot_table)\n",
    "\n",
    "# Plot the pivot table\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.heatmap(pivot_table, cmap=\"plasma\", annot=True, fmt=\"d\", linewidths=.5)\n",
    "plt.title('Youth Arrests per Quarter by First Arrest Offence')\n",
    "plt.xlabel('Year, Quarter')\n",
    "plt.ylabel('First Arrest Offence')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "348bc713518ff15d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Print distribution of 'First Arrest Offnece' for youth arrests per quarter\n",
    "offence_distribution_per_quarter = filtered_youth_arrests.groupby(['Arrest Year', 'quarter', 'First Arrest Offnece']).size().unstack(fill_value=0)\n",
    "print(\"Distribution of Youth Arrests by First Arrest Offnece per Quarter:\")\n",
    "print(offence_distribution_per_quarter)\n",
    "\n",
    "# Plot distribution\n",
    "offence_distribution_per_quarter.T.plot(kind='bar', stacked=True, figsize=(14, 8), colormap='viridis')\n",
    "plt.title('Distribution of Youth Arrests by First Arrest Offence per Quarter')\n",
    "plt.xlabel('First Arrest Offence')\n",
    "plt.ylabel('Number of Arrests')\n",
    "plt.legend(title='Year & Quarter', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a pivot table for the heatmap\n",
    "pivot_table = filtered_youth_arrests.pivot_table(\n",
    "    index='First Arrest Offnece', \n",
    "    columns=['Arrest Year', 'quarter'], \n",
    "    aggfunc='size', \n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.heatmap(pivot_table, cmap=\"plasma\", annot=True, fmt=\"d\", linewidths=.5)\n",
    "plt.title('Heatmap of Youth Arrests by First Arrest Offence per Quarter')\n",
    "plt.xlabel('Year and Quarter')\n",
    "plt.ylabel('First Arrest Offence')\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8895f828879bc72b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Melt the pas_data DataFrame to make it suitable for seaborn\n",
    "melted_data = pas_data.melt(id_vars=['borough', 'quarter'], \n",
    "                            value_vars=[col for col in pas_data.columns if 'arrests' in col],\n",
    "                            var_name='Offence_Quarter', \n",
    "                            value_name='Arrests')\n",
    "\n",
    "# Extract 'Quarter' and 'Offence' from 'Offence_Quarter' column\n",
    "melted_data[['Quarter', 'Offence']] = melted_data['Offence_Quarter'].str.extract(r'Q(\\d)_(.*)_arrests')\n",
    "\n",
    "# Convert Quarter to int\n",
    "melted_data['Quarter'] = melted_data['Quarter'].astype(int)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e4a01cc02724581"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plotting a heatmap for a clearer view of distribution per quarter\n",
    "plt.figure(figsize=(65, 45))\n",
    "pivot_heatmap = melted_data.pivot_table(index='borough', columns=['Quarter', 'Offence'], values='Arrests', aggfunc='sum', fill_value=0)\n",
    "\n",
    "# Create the heatmap with larger font sizes\n",
    "ax = sns.heatmap(pivot_heatmap, cmap='coolwarm', annot=True, fmt='g',\n",
    "                 annot_kws={'size': 20})  # Adjust this to set annotation size\n",
    "\n",
    "# Set title and axis labels with larger font sizes\n",
    "plt.title('Heatmap of Youth Arrests per Quarter by First Arrest Offence and Borough', fontsize=30)\n",
    "plt.xlabel('Quarter, Offence', fontsize=25)\n",
    "plt.ylabel('Borough', fontsize=25)\n",
    "\n",
    "# Set tick labels with larger font sizes\n",
    "plt.xticks(rotation=45, fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "\n",
    "# Set color bar label size separately\n",
    "cbar = ax.collections[0].colorbar\n",
    "cbar.set_label('Number of Arrests', fontsize=25)\n",
    "cbar.ax.tick_params(labelsize=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3956aabc26f46264"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Part 1.b split the data into 2 parts for faster running on 2 computers\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Split the data into two equal parts\n",
    "half_index = len(filtered_sas_11q) // 2\n",
    "part1 = filtered_sas_11q.iloc[:half_index]\n",
    "part2 = filtered_sas_11q.iloc[half_index:]\n",
    "\n",
    "# Save both parts as CSV files\n",
    "part1.to_csv('../data/filtered_sas_11q_part1.csv', index=False)\n",
    "part2.to_csv('../data/filtered_sas_11q_part2.csv', index=False)\n",
    "\n",
    "print(f\"Part 1 saved with {len(part1)} rows\")\n",
    "print(f\"Part 2 saved with {len(part2)} rows\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "288c5ab24886b551"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Part 2'\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "\n",
    "boroughs = [\n",
    "    \"Barking and Dagenham\",\n",
    "    \"Barnet\",\n",
    "    \"Bexley\",\n",
    "    \"Brent\",\n",
    "    \"Bromley\",\n",
    "    \"Camden\",\n",
    "    \"Croydon\",\n",
    "    \"Ealing\",\n",
    "    \"Enfield\",\n",
    "    \"Greenwich\",\n",
    "    \"Hackney\",\n",
    "    \"Hammersmith and Fulham\",\n",
    "    \"Haringey\",\n",
    "    \"Harrow\",\n",
    "    \"Havering\",\n",
    "    \"Hillingdon\",\n",
    "    \"Hounslow\",\n",
    "    \"Islington\",\n",
    "    \"Kensington and Chelsea\",\n",
    "    \"Kingston upon Thames\",\n",
    "    \"Lambeth\",\n",
    "    \"Lewisham\",\n",
    "    \"Merton\",\n",
    "    \"Newham\",\n",
    "    \"Redbridge\",\n",
    "    \"Richmond upon Thames\",\n",
    "    \"Southwark\",\n",
    "    \"Sutton\",\n",
    "    \"Tower Hamlets\",\n",
    "    \"Waltham Forest\",\n",
    "    \"Wandsworth\",\n",
    "    \"Westminster\"\n",
    "]\n",
    "filtered_sas_11q_part1 = pd.read_csv('../data/filtered_sas_11q_part1.csv')\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"eda_geolocator\")\n",
    "geocode = RateLimiter(geolocator.reverse, min_delay_seconds=1)\n",
    "\n",
    "def get_borough(lat, lon, row_index):\n",
    "    if pd.notna(lat) and pd.notna(lon):\n",
    "        start_time = time.time()  # Start time measurement\n",
    "        location = geocode((lat, lon), language='en')\n",
    "        end_time = time.time()  # End time measurement\n",
    "        elapsed_time = end_time - start_time  # Calculate elapsed time\n",
    "        print(f\"Geolocation for row {row_index} took {elapsed_time} seconds.\")\n",
    "        if location:\n",
    "            address = location.address\n",
    "            # Split the address to find the borough name, adjust the split as necessary\n",
    "            for b in boroughs:\n",
    "                if b in address:\n",
    "                    return b\n",
    "    return None\n",
    "\n",
    "# This code was used to add a Borough column that based on Latitude and Longitude\n",
    "\n",
    "filtered_sas_11q_part1['Borough'] = filtered_sas_11q_part1.apply(\n",
    "   lambda row: get_borough(row['Latitude'], row['Longitude'], row.name),  # Pass row index to function\n",
    "   axis=1\n",
    ")\n",
    "\n",
    "filtered_sas_11q_part1['Borough'] = filtered_sas_11q_part1['Borough'].fillna(\"Unknown\")\n",
    "\n",
    "filtered_sas_11q_part1.to_csv('filtered_sas_11q_part1.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "76737ade5be1b083"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "pas1 = pd.read_csv('../data/filtered_sas_part1.csv')\n",
    "pas2 = pd.read_csv('../data/filtered_sas_11q_part2.csv')\n",
    "print(pas1.info())\n",
    "print(pas2.info())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f2a2d2e17781f680"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Merge the DataFrames on the common column(s)\n",
    "# merged_filtered_sas = pd.concat([pas1, pas2], ignore_index=True)  \n",
    "\n",
    "# Display the first few rows of the merged DataFrame\n",
    "print(merged_filtered_sas)\n",
    "\n",
    "# Save the merged DataFrame to a CSV file\n",
    "# merged_filtered_sas.to_csv('../data/merged_filtered_sas.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c2a0a1c3e99aa2a6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "outcomes = pd.read_csv('../data/metropolitan-outcomes-merged.csv')\n",
    "print(outcomes.info())\n",
    "print(outcomes)\n",
    "\n",
    "# Filter out rows where 'LSOA name' is missing and create a copy to avoid SettingWithCopyWarning\n",
    "filtered_outcomes = outcomes.dropna(subset=['LSOA name']).copy()\n",
    "\n",
    "# Use .loc to assign the modified 'LSOA name' column\n",
    "filtered_outcomes.loc[:, 'LSOA name'] = filtered_outcomes['LSOA name'].apply(lambda x: x.split(' ')[0])\n",
    "\n",
    "filtered_outcomes.rename(columns={'LSOA name': 'Borough'}, inplace=True)\n",
    "\n",
    "# Display the info and first few rows to verify\n",
    "print(filtered_outcomes.info())\n",
    "print(filtered_outcomes.head())\n",
    "\n",
    "# Save the filtered and modified DataFrame to a new CSV file\n",
    "filtered_outcomes.to_csv('../data/filtered_outcomes.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "23157856fe5d35d8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the filtered outcomes data\n",
    "outcomes = pd.read_csv('../data/filtered_outcomes.csv')\n",
    "\n",
    "# Define the list of boroughs to filter\n",
    "boroughs = [\n",
    "    \"Barking and Dagenham\",\n",
    "    \"Barking\",\n",
    "    \"Barnet\",\n",
    "    \"Bexley\",\n",
    "    \"Brent\",\n",
    "    \"Bromley\",\n",
    "    \"Camden\",\n",
    "    \"Croydon\",\n",
    "    \"Ealing\",\n",
    "    \"Enfield\",\n",
    "    \"Greenwich\",\n",
    "    \"Hackney\",\n",
    "    \"Hammersmith and Fulham\",\n",
    "    \"Hammersmith\",\n",
    "    \"Haringey\",\n",
    "    \"Harrow\",\n",
    "    \"Havering\",\n",
    "    \"Hillingdon\",\n",
    "    \"Hounslow\",\n",
    "    \"Islington\",\n",
    "    \"Kensington and Chelsea\",\n",
    "    \"Kensington\",\n",
    "    \"Chelsea\",\n",
    "    \"Kennington\",\n",
    "    \"Kingston upon Thames\",\n",
    "    \"Kingston\",\n",
    "    \"Lambeth\",\n",
    "    \"Lewisham\",\n",
    "    \"Merton\",\n",
    "    \"Newham\",\n",
    "    \"Redbridge\",\n",
    "    \"Richmond upon Thames\",\n",
    "    \"Richmond\",\n",
    "    \"Southwark\",\n",
    "    \"Sutton\",\n",
    "    \"Tower Hamlets\",\n",
    "    \"Tower\",\n",
    "    \"Waltham Forest\",\n",
    "    \"Waltham\",\n",
    "    \"Wandsworth\",\n",
    "    \"Westminster\"\n",
    "]\n",
    "\n",
    "# Filter the dataframe to include only the specified boroughs\n",
    "filtered_outcomes = outcomes[outcomes['Borough'].isin(boroughs)]\n",
    "\n",
    "# Print the counts for each of these boroughs\n",
    "borough_counts = filtered_outcomes['Borough'].value_counts()\n",
    "print(borough_counts.head(35))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "db6b71f9ddc53236"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load the filtered outcomes data\n",
    "outcomes = filtered_outcomes\n",
    "\n",
    "# Define the mappings for short names to full borough names\n",
    "borough_replacements = {\n",
    "    \"Barking\": \"Barking and Dagenham\",\n",
    "    \"Hammersmith\": \"Hammersmith and Fulham\",\n",
    "    \"Kensington\": \"Kensington and Chelsea\",\n",
    "    \"Kingston\": \"Kingston upon Thames\",\n",
    "    \"Richmond\": \"Richmond upon Thames\",\n",
    "    \"Tower\": \"Tower Hamlets\",\n",
    "    \"Waltham\": \"Waltham Forest\"\n",
    "}\n",
    "\n",
    "# Replace the short borough names with the full names\n",
    "outcomes['Borough'] = outcomes['Borough'].replace(borough_replacements)\n",
    "\n",
    "# Print the counts for each of these boroughs\n",
    "borough_counts = outcomes['Borough'].value_counts()\n",
    "print(borough_counts)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1569371a26356623"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Ensure 'Month' is in datetime format\n",
    "outcomes['Month'] = pd.to_datetime(outcomes['Month'])\n",
    "\n",
    "# Extract year and quarter\n",
    "outcomes['Year'] = outcomes['Month'].dt.year\n",
    "outcomes['Quarter'] = outcomes['Month'].dt.quarter\n",
    "\n",
    "# Aggregate by Borough, Year, and Quarter\n",
    "aggregated_outcomes = outcomes.groupby(['Borough', 'Year', 'Quarter']).size().reset_index(name='Count')\n",
    "\n",
    "# Print the resulting aggregated DataFrame\n",
    "print(aggregated_outcomes)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c4320a7613f746a8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "# Convert 'Year' and 'Quarter' columns to match the data type of the other DataFrame\n",
    "aggregated_outcomes['Year'] = aggregated_outcomes['Year'].astype(str)\n",
    "aggregated_outcomes['Quarter'] = aggregated_outcomes['Quarter'].astype(float)\n",
    "\n",
    "# Sort the DataFrame by Borough, Year, and Quarter\n",
    "aggregated_outcomes_sorted = aggregated_outcomes.sort_values(by=['Borough', 'Year', 'Quarter'])\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a9b56ec51a9cbee8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame to hold the new rows\n",
    "new_rows = []\n",
    "\n",
    "# Iterate through each unique Borough and Year in the DataFrame\n",
    "for borough in aggregated_outcomes_sorted['Borough'].unique():\n",
    "    for year in aggregated_outcomes_sorted['Year'].unique():\n",
    "        # Filter the DataFrame for the specific Borough and Year\n",
    "        df_filtered = aggregated_outcomes_sorted[(aggregated_outcomes_sorted['Borough'] == borough) & (aggregated_outcomes_sorted['Year'] == year)]\n",
    "        \n",
    "        # Check if the filtered DataFrame has data for quarters 2, 3, and 4\n",
    "        if len(df_filtered) == 3:\n",
    "            # Calculate the average count for quarters 2, 3, and 4\n",
    "            avg_count = df_filtered['Count'].mean()\n",
    "            \n",
    "            # Append a new row for Quarter 1\n",
    "            new_rows.append({'Borough': borough, 'Year': year, 'Quarter': 1.0, 'Count': avg_count})\n",
    "\n",
    "# Convert the new rows to a DataFrame and append to the original DataFrame\n",
    "new_rows_df = pd.DataFrame(new_rows)\n",
    "aggregated_outcomes_updated = pd.concat([aggregated_outcomes_sorted, new_rows_df], ignore_index=True)\n",
    "\n",
    "# Sort the final DataFrame by Borough, Year, and Quarter\n",
    "aggregated_outcomes_final = aggregated_outcomes_final.sort_values(by=['Borough', 'Year', 'Quarter']).reset_index(drop=True)\n",
    "\n",
    "# Print the final DataFrame info to verify the row count\n",
    "print(aggregated_outcomes_final.info())\n",
    "print(aggregated_outcomes_final)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d4dd1a09b2e70a8e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Define the unique boroughs\n",
    "pas_final = pd.read_csv('../data/pas_final.csv')\n",
    "# Iterate through the DataFrame\n",
    "new_rows = []\n",
    "\n",
    "for index, row in pas_final.iterrows():\n",
    "    if row['Year'] == 2023 and row['Quarter'] == 4.0:\n",
    "        # Save the values\n",
    "        new_row = row.copy()\n",
    "        new_row['Year'] = 2021\n",
    "        new_row['Quarter'] = 1.0\n",
    "        new_rows.append(new_row)\n",
    "        # Drop the current row\n",
    "        pas_final.drop(index, inplace=True)\n",
    "\n",
    "# Add the new rows for Year 2021 and Quarter 1\n",
    "pas_final = pd.concat([pas_final, pd.DataFrame(new_rows)], ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "88d94461ad39f92f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "dbee08a3395bb3d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9da0575d6feb6270"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ef3e4fa0e3ebe8a0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
